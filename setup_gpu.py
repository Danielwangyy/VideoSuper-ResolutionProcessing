#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUåŠ é€Ÿç¯å¢ƒé…ç½®è„šæœ¬
æ£€æµ‹ç³»ç»Ÿç¯å¢ƒå¹¶ä¼˜åŒ–é…ç½®ï¼Œæ”¯æŒApple MPSå’ŒNVIDIA CUDA
"""

import sys
import os
import platform
import subprocess
import importlib
import time
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GPUSetup:
    def __init__(self):
        self.system_info = self._get_system_info()
        self.gpu_type = None
        self.recommendations = []
    
    def _get_system_info(self):
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        info = {
            'platform': platform.system(),
            'machine': platform.machine(),
            'python_version': platform.python_version(),
            'processor': platform.processor()
        }
        
        # æ£€æµ‹Apple Silicon
        if info['platform'] == 'Darwin' and info['machine'] == 'arm64':
            info['is_apple_silicon'] = True
        else:
            info['is_apple_silicon'] = False
            
        return info
    
    def check_pytorch_installation(self):
        """æ£€æŸ¥PyTorchå®‰è£…æƒ…å†µ"""
        logger.info("ğŸ” æ£€æŸ¥PyTorchå®‰è£…æƒ…å†µ...")
        
        try:
            import torch
            import torchvision
            
            logger.info(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
            logger.info(f"âœ… TorchVisionç‰ˆæœ¬: {torchvision.__version__}")
            
            # æ£€æŸ¥ç¼–è¯‘ç‰ˆæœ¬ä¿¡æ¯
            logger.info(f"ğŸ“Š PyTorchç¼–è¯‘ä¿¡æ¯:")
            logger.info(f"   - CUDAç¼–è¯‘æ”¯æŒ: {torch.version.cuda is not None}")
            if torch.version.cuda:
                logger.info(f"   - CUDAç‰ˆæœ¬: {torch.version.cuda}")
            
            return True
            
        except ImportError as e:
            logger.error(f"âŒ PyTorchæœªå®‰è£…: {e}")
            self.recommendations.append("å®‰è£…PyTorch: pip install torch torchvision")
            return False
    
    def check_gpu_support(self):
        """æ£€æŸ¥GPUæ”¯æŒæƒ…å†µ"""
        logger.info("ğŸš€ æ£€æŸ¥GPUæ”¯æŒæƒ…å†µ...")
        
        try:
            import torch
            
            # æ£€æŸ¥CUDAæ”¯æŒ
            cuda_available = torch.cuda.is_available()
            logger.info(f"NVIDIA CUDAå¯ç”¨: {cuda_available}")
            
            if cuda_available:
                self.gpu_type = 'cuda'
                logger.info(f"   - CUDAè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
                for i in range(torch.cuda.device_count()):
                    logger.info(f"   - GPU {i}: {torch.cuda.get_device_name(i)}")
                    
                # CUDAæ€§èƒ½æµ‹è¯•
                self._test_cuda_performance()
            
            # æ£€æŸ¥MPSæ”¯æŒï¼ˆApple Siliconï¼‰
            if hasattr(torch.backends, 'mps'):
                mps_available = torch.backends.mps.is_available()
                mps_built = torch.backends.mps.is_built()
                
                logger.info(f"Apple MPSå¯ç”¨: {mps_available}")
                logger.info(f"Apple MPSå·²æ„å»º: {mps_built}")
                
                if mps_available and not cuda_available:
                    self.gpu_type = 'mps'
                    # MPSæ€§èƒ½æµ‹è¯•
                    self._test_mps_performance()
            
            if not cuda_available and not (hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()):
                self.gpu_type = 'cpu'
                logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°GPUåŠ é€Ÿæ”¯æŒï¼Œå°†ä½¿ç”¨CPU")
                
        except Exception as e:
            logger.error(f"âŒ GPUæ£€æŸ¥å¤±è´¥: {e}")
            self.gpu_type = 'cpu'
    
    def _test_cuda_performance(self):
        """æµ‹è¯•CUDAæ€§èƒ½"""
        try:
            import torch
            
            logger.info("ğŸ§ª CUDAæ€§èƒ½æµ‹è¯•...")
            device = torch.device('cuda')
            
            # çŸ©é˜µä¹˜æ³•æµ‹è¯•
            size = 2000
            start_time = time.time()
            
            a = torch.randn(size, size, device=device)
            b = torch.randn(size, size, device=device)
            c = torch.matmul(a, b)
            torch.cuda.synchronize()  # ç¡®ä¿è®¡ç®—å®Œæˆ
            
            cuda_time = time.time() - start_time
            logger.info(f"   - CUDAçŸ©é˜µä¹˜æ³•({size}x{size}): {cuda_time:.3f}ç§’")
            
            # å†…å­˜ä¿¡æ¯
            memory_allocated = torch.cuda.memory_allocated() / 1024**3
            memory_reserved = torch.cuda.memory_reserved() / 1024**3
            logger.info(f"   - GPUå†…å­˜ä½¿ç”¨: {memory_allocated:.2f}GB / {memory_reserved:.2f}GB")
            
        except Exception as e:
            logger.warning(f"âš ï¸ CUDAæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    def _test_mps_performance(self):
        """æµ‹è¯•MPSæ€§èƒ½"""
        try:
            import torch
            
            logger.info("ğŸ§ª MPSæ€§èƒ½æµ‹è¯•...")
            device = torch.device('mps')
            
            # çŸ©é˜µä¹˜æ³•æµ‹è¯•
            size = 2000
            start_time = time.time()
            
            a = torch.randn(size, size, device=device)
            b = torch.randn(size, size, device=device)
            c = torch.matmul(a, b)
            
            mps_time = time.time() - start_time
            logger.info(f"   - MPSçŸ©é˜µä¹˜æ³•({size}x{size}): {mps_time:.3f}ç§’")
            
            # CPUå¯¹æ¯”æµ‹è¯•
            start_time = time.time()
            a_cpu = torch.randn(size, size)
            b_cpu = torch.randn(size, size)
            c_cpu = torch.matmul(a_cpu, b_cpu)
            cpu_time = time.time() - start_time
            
            speedup = cpu_time / mps_time if mps_time > 0 else 1
            logger.info(f"   - CPUçŸ©é˜µä¹˜æ³•({size}x{size}): {cpu_time:.3f}ç§’")
            logger.info(f"   - MPSåŠ é€Ÿæ¯”: {speedup:.1f}x")
            
        except Exception as e:
            logger.warning(f"âš ï¸ MPSæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    def check_realesrgan_compatibility(self):
        """æ£€æŸ¥Real-ESRGANå…¼å®¹æ€§"""
        logger.info("ğŸ” æ£€æŸ¥Real-ESRGANå…¼å®¹æ€§...")
        
        try:
            # æ£€æŸ¥basicsr
            import basicsr
            logger.info(f"âœ… BasicSRç‰ˆæœ¬: {basicsr.__version__}")
            
            # æ£€æŸ¥realesrgan
            import realesrgan
            logger.info(f"âœ… RealESRGANç‰ˆæœ¬: {realesrgan.__version__}")
            
            # å°è¯•å¯¼å…¥å…³é”®æ¨¡å—
            from realesrgan import RealESRGANer
            from realesrgan.archs.srvgg_arch import SRVGGNetCompact
            from basicsr.archs.rrdbnet_arch import RRDBNet
            
            logger.info("âœ… Real-ESRGANæ¨¡å—å¯¼å…¥æˆåŠŸ")
            
            # æ£€æŸ¥known issues
            self._check_known_issues()
            
            return True
            
        except ImportError as e:
            logger.error(f"âŒ Real-ESRGANä¾èµ–ç¼ºå¤±: {e}")
            self.recommendations.append("å®‰è£…Real-ESRGAN: pip install realesrgan basicsr")
            return False
        except Exception as e:
            logger.error(f"âŒ Real-ESRGANå…¼å®¹æ€§é—®é¢˜: {e}")
            return False
    
    def _check_known_issues(self):
        """æ£€æŸ¥å·²çŸ¥å…¼å®¹æ€§é—®é¢˜"""
        try:
            import torch
            import torchvision
            
            # æ£€æŸ¥torchvisionç‰ˆæœ¬å…¼å®¹æ€§
            tv_version = torchvision.__version__
            major, minor = map(int, tv_version.split('.')[:2])
            
            if major > 0 or (major == 0 and minor >= 13):
                # æ–°ç‰ˆæœ¬å¯èƒ½æœ‰functional_tensoré—®é¢˜
                try:
                    from torchvision.transforms.functional_tensor import rgb_to_grayscale
                    logger.warning("âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„functional_tensorå…¼å®¹æ€§é—®é¢˜")
                    self.recommendations.append("å¯èƒ½éœ€è¦ä¿®å¤BasicSRä¸­çš„functional_tensorå¯¼å…¥é—®é¢˜")
                except ImportError:
                    # è¿™æ˜¯é¢„æœŸçš„ï¼Œæ–°ç‰ˆæœ¬å·²ç»ç§»é™¤äº†functional_tensoræ¨¡å—
                    logger.info("âœ… TorchVisionç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥é€šè¿‡")
                    
        except Exception as e:
            logger.warning(f"âš ï¸ å…¼å®¹æ€§æ£€æŸ¥å¤±è´¥: {e}")
    
    def optimize_environment(self):
        """ä¼˜åŒ–ç¯å¢ƒè®¾ç½®"""
        logger.info("ğŸ”§ ä¼˜åŒ–ç¯å¢ƒè®¾ç½®...")
        
        if self.gpu_type == 'mps':
            # Apple MPSä¼˜åŒ–
            os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
            os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
            logger.info("âœ… Apple MPSç¯å¢ƒå˜é‡å·²è®¾ç½®")
            
        elif self.gpu_type == 'cuda':
            # CUDAä¼˜åŒ–
            os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
            os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # å¼‚æ­¥æ‰§è¡Œ
            logger.info("âœ… CUDAç¯å¢ƒå˜é‡å·²è®¾ç½®")
        
        # é€šç”¨ä¼˜åŒ–
        os.environ['OMP_NUM_THREADS'] = str(os.cpu_count())
        logger.info(f"âœ… OpenMPçº¿ç¨‹æ•°è®¾ç½®ä¸º: {os.cpu_count()}")
    
    def generate_config_file(self):
        """ç”Ÿæˆé…ç½®æ–‡ä»¶"""
        config_content = f"""# GPUåŠ é€Ÿé…ç½®æ–‡ä»¶
# è‡ªåŠ¨ç”Ÿæˆäº: {time.strftime('%Y-%m-%d %H:%M:%S')}

[system]
platform = {self.system_info['platform']}
machine = {self.system_info['machine']}
is_apple_silicon = {self.system_info['is_apple_silicon']}

[gpu]
type = {self.gpu_type}
recommended_device = {self.gpu_type}

[optimization]
"""
        
        if self.gpu_type == 'mps':
            config_content += """tile_size = 256
precision = fp32
batch_size = 1
"""
        elif self.gpu_type == 'cuda':
            config_content += """tile_size = 512
precision = fp16
batch_size = 2
"""
        else:
            config_content += """tile_size = 128
precision = fp32
batch_size = 1
"""
        
        with open('gpu_config.ini', 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        logger.info("âœ… é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: gpu_config.ini")
    
    def print_summary(self):
        """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
        logger.info("=" * 60)
        logger.info("ğŸ“Š GPUåŠ é€Ÿç¯å¢ƒé…ç½®æ€»ç»“")
        logger.info("=" * 60)
        
        # ç³»ç»Ÿä¿¡æ¯
        logger.info("ğŸ–¥ï¸ ç³»ç»Ÿä¿¡æ¯:")
        logger.info(f"   - æ“ä½œç³»ç»Ÿ: {self.system_info['platform']}")
        logger.info(f"   - æ¶æ„: {self.system_info['machine']}")
        logger.info(f"   - Pythonç‰ˆæœ¬: {self.system_info['python_version']}")
        if self.system_info['is_apple_silicon']:
            logger.info("   - Apple Silicon: âœ…")
        
        # GPUä¿¡æ¯
        logger.info(f"ğŸš€ æ¨èGPUè®¾å¤‡: {self.gpu_type.upper()}")
        
        if self.gpu_type == 'mps':
            logger.info("ğŸ Apple MPSé…ç½®:")
            logger.info("   - åˆ†å—å¤§å°: 256")
            logger.info("   - ç²¾åº¦: FP32")
            logger.info("   - é¢„æœŸåŠ é€Ÿæ¯”: 2-5x")
        elif self.gpu_type == 'cuda':
            logger.info("ğŸ”¥ NVIDIA CUDAé…ç½®:")
            logger.info("   - åˆ†å—å¤§å°: 512")
            logger.info("   - ç²¾åº¦: FP16")
            logger.info("   - é¢„æœŸåŠ é€Ÿæ¯”: 5-20x")
        else:
            logger.info("ğŸ’» CPUé…ç½®:")
            logger.info("   - åˆ†å—å¤§å°: 128")
            logger.info("   - ç²¾åº¦: FP32")
        
        # æ¨èæ“ä½œ
        if self.recommendations:
            logger.info("ğŸ’¡ å»ºè®®æ“ä½œ:")
            for rec in self.recommendations:
                logger.info(f"   - {rec}")
        
        # ä½¿ç”¨ç¤ºä¾‹
        logger.info("ğŸ¯ ä½¿ç”¨ç¤ºä¾‹:")
        logger.info(f"   python3 video_super_resolution_gpu.py -i input.mp4 -o output.mp4 --device {self.gpu_type}")
        
        logger.info("=" * 60)


def main():
    logger.info("ğŸš€ å¼€å§‹GPUåŠ é€Ÿç¯å¢ƒé…ç½®...")
    
    setup = GPUSetup()
    
    # æ­¥éª¤1: æ£€æŸ¥PyTorch
    pytorch_ok = setup.check_pytorch_installation()
    
    # æ­¥éª¤2: æ£€æŸ¥GPUæ”¯æŒ
    if pytorch_ok:
        setup.check_gpu_support()
    
    # æ­¥éª¤3: æ£€æŸ¥Real-ESRGANå…¼å®¹æ€§
    if pytorch_ok:
        setup.check_realesrgan_compatibility()
    
    # æ­¥éª¤4: ä¼˜åŒ–ç¯å¢ƒ
    setup.optimize_environment()
    
    # æ­¥éª¤5: ç”Ÿæˆé…ç½®æ–‡ä»¶
    setup.generate_config_file()
    
    # æ­¥éª¤6: æ‰“å°æ€»ç»“
    setup.print_summary()
    
    logger.info("âœ… GPUåŠ é€Ÿç¯å¢ƒé…ç½®å®Œæˆ!")
    
    return 0


if __name__ == '__main__':
    exit(main()) 